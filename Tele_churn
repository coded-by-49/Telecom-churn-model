{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1oGemtDSZlkkLbD3DnJGBpGikPkftxJ7I","authorship_tag":"ABX9TyOKTT4vNy8Qxl009i1UVg9Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"vMaDxPOapKgj"}},{"cell_type":"code","source":["# !ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N '' # generate my ssh key encryrpt it and store it . it will be accessed by an empty string\n","# !cat ~/.ssh/id_ed25519.pub # print the public key\n","!chmod 700 ~/.ssh # i want secure and personal access to it\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts # make recognise github\n","!ssh -T git@github.com\n","!git clone git@github.com:coded-by-49/Telecom-churn-model.git # cloning my repo into collab\n","%cd Telecom-churn-model\n","!git config --global user.name \"coded-by-49\" # setting up global identity\n","!git config --global user.email \"fabianbernard49@gmail.com\"\n","# !git config --global --list | grep \"user.name\\|user.email\" # checking whether my identity is setup\n","# i renamed my file with mv\n","\n","# from google.colab import _message\n","# _message.blocking_request('clear_output', {})\n","\n","\n","\n"],"metadata":{"id":"Vo0RQxz9f2bm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752504293457,"user_tz":-60,"elapsed":2139,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"d21ad35e-9302-488d-d494-b2f69aa803ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# github.com:22 SSH-2.0-a9c4b169\n","# github.com:22 SSH-2.0-a9c4b169\n","# github.com:22 SSH-2.0-a9c4b169\n","# github.com:22 SSH-2.0-a9c4b169\n","# github.com:22 SSH-2.0-a9c4b169\n","Hi coded-by-49! You've successfully authenticated, but GitHub does not provide shell access.\n","Cloning into 'Telecom-churn-model'...\n","remote: Enumerating objects: 14, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 14 (delta 3), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (14/14), 8.16 KiB | 8.16 MiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n","/content/Telecom-churn-model\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":["from itertools import groupby\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","from IPython.display import clear_output\n","import tensorflow as tf\n","fc = tf.compat.v2.feature_column\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# GET OUR THE FILE READY\n","from google.colab import drive\n","import urllib\n","drive.mount('/content/drive')\n","tele_file = \"/content/drive/MyDrive/GOOGLE COLLAB PROJECTS/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n","df_tele = pd.read_csv(tele_file)\n","\n","# LEARNIN ALGORITHM\n","from sklearn.linear_model import LogisticRegression\n","df_tele.drop(\"customerID\", axis = 1, inplace = True) # removed this unimportant feature\n","\n","# CLEANING OF DATA\n","df_tele[\"TotalCharges\"] = df_tele[\"TotalCharges\"].replace(\" \", np.nan) # replacing empty strings np.nan, to that i can convert it to float\n","df_tele.dropna(subset = [\"TotalCharges\"], inplace=True) # cleaded out the array by dropping does empty values within the Totalcharges feature\n","df_tele[\"TotalCharges\"] = pd.to_numeric(df_tele[\"TotalCharges\"]) # coverted to float because of the kind of content within totalcharges\n","\n","# ENCODING OF ALL CATEGORICAL FEATURES\n","encoded = pd.get_dummies(df_tele, drop_first= True ) # this is one-hot key encoding (we want to transform all our categorical columns into )\n","encoded.head()\n","\n","# CHANGING THE DATATYPE OF BINARY CATEGORICAL FEATURES\n","bool_cols = encoded.select_dtypes(include = \"bool\").columns #select all columns with bool datatype\n","encoded[bool_cols] = encoded[bool_cols].astype(int) #change all of them to int (0 and 1)\n","\n","encoded[\"tenure\"] = encoded[\"tenure\"].astype(float)\n","all_numerical_features = encoded.select_dtypes(include = np.number).columns.tolist()\n","\n","needed_numerical_feature = [feature for feature in all_numerical_features if encoded[feature].nunique()>2] # getting the numerical feature titles ready\n","\n","Labels = encoded[\"Churn_Yes\"]\n","Features = encoded.drop(\"Churn_Yes\", axis = 1)\n","\n","# OBTANING OUR TRANING AND TEST DATA\n","X_train, X_test, Y_train, Y_test = train_test_split(Features,Labels, test_size = 0.2, random_state = 42 )\n","# SCALLING AND PREPARING OUR TRAINING AND TESTING DATA\n","Scaler = StandardScaler()\n","\n","# let us fit and tranform  our training numerical-features\n","X_train[needed_numerical_feature] = Scaler.fit_transform(X_train[needed_numerical_feature])\n","\n","# let us apply the scaling parameters gotten from above and fit it to our testing numerical-features\n","X_test[needed_numerical_feature] = Scaler.transform(X_test[needed_numerical_feature])\n","\n","log_regression = LogisticRegression(max_iter=1000) # is max_iter really needed?\n","log_regression.fit(X_train, Y_train) # FIT THIS WHERE OUR WEIGHT AND BIAS ARE DERVIED FROM\n","\n","# print(f\"Testing accuracy: {log_regression.score(X_test, Y_test)}\") # SCORE THE TEST DATA\n","\n","# LOGISTC REGRESSION FROM SCRATCH\n","\n","class Logistic_regression:\n","  def __init__(self, learning_rate = 0.01, n_iters = 1000):\n","    self.learning_rate = learning_rate\n","    self.n_iters = n_iters\n","\n","  def sigmoid(self,z):\n","    return 1/(1+np.exp(-z))\n","\n","  '''\n","  CORE\n","  This is responsible deriving weight and bias of a several feature(s).\n","  This is important, because when we want to derive predictions on any future dataset this are the exact values we will use\n","  '''\n","\n","  def fit(self,X,Y):\n","    self.num_samples, self.num_features = X.shape #lets count the number of features and dataitems(rows)\n","    self.weights = np.zeros(self.num_features)\n","    self.bias = 0\n","\n","    for _ in range(self.n_iters):\n","      Y_num_prediction = np.dot(X, self.weights) + self.bias\n","      Y_predicted = self.sigmoid(Y_num_prediction)\n","\n","      # implementing gradient descent\n","\n","      # we are implementing the average our two derivatives of the loss function\n","      dw = np.dot(X.T,(Y_predicted - Y))/self.num_samples\n","      db = np.mean((Y_predicted - Y))\n","\n","      # adjust weights after each iteration with learning rate\n","      self.weights = self.weights - self.learning_rate * dw\n","      self.bias = self.bias - self.learning_rate * db\n","\n","      # stoping condition with eculidean normalisation\n","      if np.linalg.norm(db) < 0.001 and np.linalg.norm(dw) < 0.001:\n","        break\n","\n","# This function is used for determining the accuracy score\n","  def score(self, X_test,Y_test):\n","    Y_num_prediction = np.dot(X_test, self.weights) + self.bias\n","    self.Y_predicted = self.sigmoid(Y_num_prediction)\n","    self.Y_predicted = np.where(self.Y_predicted > 0.5, 1, 0)\n","    accuracy =  np.mean(self.Y_predicted == Y_test)\n","    return accuracy\n","\n","  def Confusion_matrix(self,predicted_class,actual_class):\n","    confusion_matrix = {\n","    'TP': 0,\n","    'TN': 0,\n","    'FP': 0,\n","    'FN': 0\n","    }\n","    for i in range(len(actual_class)):\n","      if predicted_class[i] == actual_class.iloc[i]:\n","        if predicted_class[i] == 1:\n","            confusion_matrix[\"TP\"] += 1\n","        else:\n","            confusion_matrix[\"TN\"] += 1\n","      else:\n","        if actual_class.iloc[i] == 0:\n","            confusion_matrix[\"FP\"] += 1\n","        else:\n","            confusion_matrix[\"FN\"] += 1\n","    return confusion_matrix\n","\n","test_model = Logistic_regression()\n","test_model.fit(X_train, Y_train)\n","print(f\"Accuracy on test models: {test_model.score(X_test,Y_test)}\")\n","\"TESTING MY CONFUSION MATRIX\"\n","predicted_class = test_model.Y_predicted\n","actual_class = Y_test\n","print(f\"Confusion matrix = {test_model.Confusion_matrix(predicted_class,actual_class)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSZYHGtHS1xS","executionInfo":{"status":"ok","timestamp":1752500767964,"user_tz":-60,"elapsed":8695,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"1a96b47b-5b82-4e08-b6ac-ec3d875a4f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Accuracy on test models: 0.7903340440653873\n","Confusion matrix = {'TP': 171, 'TN': 941, 'FP': 92, 'FN': 203}\n"]}]},{"cell_type":"code","source":["from IPython import get_ipython\n","\n","ipython = get_ipython()\n","notebook_path = ipython.run_line_magic('pwd', '')\n","print(\"Notebook is running in:\", notebook_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rL4xef_QL2lS","executionInfo":{"status":"ok","timestamp":1752506477855,"user_tz":-60,"elapsed":20,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"2cb6a2b7-617c-4840-c087-16d189a96e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Notebook is running in: /content/Telecom-churn-model\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"wF9Z1QPBMNVo"}},{"cell_type":"markdown","source":[],"metadata":{"id":"flVAsgdjMNEZ"}},{"cell_type":"code","metadata":{"id":"20b10840","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"error","timestamp":1752507138870,"user_tz":-60,"elapsed":152,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"93fba39d-9bf1-4c37-8f94-5ea8a2c392ca"},"source":["!mv \"/content/drive/MyDrive/Tele_churn\" \"/content/Telecom-churn-model/\""],"execution_count":24,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/Telecom-churn-model/drive'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-24-4076646975.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Telecom-churn-model/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Telecom-churn-model/drive'"]}]}]}