{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":16614,"status":"ok","timestamp":1752853749357,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"},"user_tz":-60},"id":"cTN7maFWg2rM","outputId":"286da1c9-0a0a-441d-a186-f016f5e8dd1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["# github.com:22 SSH-2.0-1581bab2\n","# github.com:22 SSH-2.0-1581bab2\n","# github.com:22 SSH-2.0-1581bab2\n","# github.com:22 SSH-2.0-1581bab2\n","# github.com:22 SSH-2.0-1581bab2\n","Hi coded-by-49! You've successfully authenticated, but GitHub does not provide shell access.\n","/content/drive/MyDrive/Git_repos/Telecom-churn-model\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   Tele_churn.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","[main 143376c] Optimisation of Model precision and recall using feature engineering\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Tele_churn.ipynb (100%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (2/2), done.\n","Writing objects: 100% (3/3), 2.67 KiB | 143.00 KiB/s, done.\n","Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To github.com:coded-by-49/Telecom-churn-model.git\n","   e7b3f32..143376c  main -> main\n"]}],"source":["  '''\n","  PUSING MY COLLAB PROJECT TO GITHUB\n","  '''\n","# !ssh-keygen -t rsa -b 4096 -C \"fabianbernard49@gmail.com\" -f ~/.ssh/id_rsa -N \"\"  #Create ssh pair key\n","# !cat ~/.ssh/id_rsa.pub #Print out your\n","!ssh-keyscan -H github.com >> ~/.ssh/known_hosts #Make github a knownhost\n","!ssh -T git@github.com #Aunthenticate github\n","\n","  # Verify your identity\n","!git config --global user.name \"coded-by-49\"\n","!git config --global user.email \"fabianbernard49@gmail.com\"\n","\n","# %cd /content/drive/MyDrive/Git_repos #Create a folder for git hub repos if its your first time\n","# %cd /content/drive/MyDrive/Git_repos/Telecom-churn-model/ #Enter that folder\n","# !git clone git@github.com:coded-by-49/Telecom-churn-model.git  #Clone your repo into it\n","\n","#Copy your project note-book progress into it and open the directory were your copy is stored\n","!cp \"/content/drive/MyDrive/Colab Notebooks/Tele_churn.ipynb\" /content/drive/MyDrive/Git_repos/Telecom-churn-model/ #Copy your project note-book progress into it\n","%cd /content/drive/MyDrive/Git_repos/Telecom-churn-model # open the directory were your copy is stored\n","!git status\n","!git add Tele_churn.ipynb #Add the file itself to avoid json file upload in repo\n","!git commit -m \"Optimisation of Model precision and recall using feature engineering\"\n","!git push origin main"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfQaQpg8efAJ","executionInfo":{"status":"ok","timestamp":1752853407287,"user_tz":-60,"elapsed":100807,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"f1190eac-5238-481e-a2a4-cdadf7b37ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Best parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'class_weight': {0: 1, 1: 1.5}}\n","Best Cross-Validation Recall: 0.8325\n","Accuracy: 0.7306\n","Confusion Matrix: [TN=748, FP=285, FN=94, TP=280\n","Recall: 0.7487\n","Precision: 0.4956\n","F1_score: 0.5964\n"]}],"source":["from itertools import groupby\n","import numpy as np\n","import pandas as pd\n","from IPython.display import clear_output\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","'''Data Preprocessing'''\n","from google.colab import drive\n","import urllib\n","\n","# Importing file from googledrive\n","drive.mount('/content/drive')\n","tele_churn_csv = \"/content/drive/MyDrive/GOOGLE COLLAB PROJECTS/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n","df_tele = pd.read_csv(tele_churn_csv)\n","\n","# Cleaning out empty feature spots\n","df_tele[\"TotalCharges\"] = df_tele[\"TotalCharges\"].replace(\" \", np.nan)\n","df_tele.dropna(subset = [\"TotalCharges\"], inplace=True)\n","df_tele[\"TotalCharges\"] = pd.to_numeric(df_tele[\"TotalCharges\"])\n","\n","# Dropping unimportant features\n","df_tele.drop(\"customerID\", axis = 1, inplace = True) # removed this unimportant feature\n","\n","###### FEATURE ENGINNEERING\n","# Create the new column based on the two conditions\n","bins = [0,15,48,73]\n","labels = [\"New_customers\", \"Established_customers\", \"Loyal_customers\"]\n","df_tele['Tenure_Group'] = pd.cut(df_tele['tenure'], bins=bins, labels=labels, right=False)\n","df_tele['HighRisk_Interaction'] = ((df_tele['Contract'] == 'Month-to-month') & (df_tele['InternetService'] == 'Fiber optic')).astype(int)\n","df_tele['Tenure_MonthlyCharges'] = df_tele['tenure'] * df_tele['MonthlyCharges']\n","\n","# Encoding our dataframe\n","encoded_df_tele = pd.get_dummies(df_tele, drop_first= True )\n","encoded_df_tele.head()\n","\n","# Conversion of boolean columns into zeros and ones\n","bool_cols = encoded_df_tele.select_dtypes(include = \"bool\").columns\n","encoded_df_tele[bool_cols] = encoded_df_tele[bool_cols].astype(int)\n","\n","###### FEATURE ENGINNEERING\n","encoded_df_tele['Fiber_Electronic'] = ((encoded_df_tele['InternetService_Fiber optic'] == 1) & (encoded_df_tele['PaymentMethod_Electronic check'] == 1)).astype(int)\n","\n","\n","# Conversion of tenure datatype numerical datatype\n","encoded_df_tele[\"tenure\"] = encoded_df_tele[\"tenure\"].astype(float)\n","\n","# Storing all the numerical feature titles\n","all_numerical_features = encoded_df_tele.select_dtypes(include = np.number).columns.tolist()\n","needed_numerical_feature = [feature for feature in all_numerical_features if encoded_df_tele[feature].nunique()>2]\n","\n","\n","# Separation of future and labels\n","labels = encoded_df_tele[\"Churn_Yes\"]\n","features = encoded_df_tele.drop(\"Churn_Yes\", axis = 1)\n","\n","# Creating our testing and training data\n","x_train, x_test, y_train, y_test = train_test_split(features,labels, test_size = 0.2, random_state = 42 )\n","\n","# Scaling our non-categoical numerical features\n","Scaler = StandardScaler()\n","x_train[needed_numerical_feature] = Scaler.fit_transform(x_train[needed_numerical_feature])\n","x_test[needed_numerical_feature] = Scaler.transform(x_test[needed_numerical_feature])\n","\n","\n","\"\"\"IMPLEMENTATION OF LOGISTIC REGRESSION ALGORITHM FROM SCRATCH\"\"\"\n","################# THIS MODEL HAS BEEN TESTED\n","class custom_Log_regression:\n","  '''\n","      Attributes:\n","        learning_rate (float): Step size for gradient descent updates.\n","        n_iters (int): Maximum number of iterations for training.\n","  '''\n","  def __init__(self, learning_rate = 0.01, n_iters = 1000):\n","    self.learning_rate = learning_rate\n","    self.n_iters = n_iters\n","\n","  def sigmoid(self,z):\n","    '''\n","       Sigmoid function, used for transformation of numerical prediction to 1's and 0's\n","       Args:\n","            z (numpy.ndarray): Input values (linear combination of features and weights).\n","       Our sigmoid then transfroms it into an array numpy.ndarray of probablilities between 0 and 1\n","    '''\n","    return 1/(1+np.exp(-z))\n","\n","  def fit(self,X,Y):\n","    '''\n","    (Training function) Fit function would derive the weight and bias that\n","     occurs during the two minimum derivative of the loss function\n","\n","    Args:\n","        X (numpy.ndarray): Training features (shape: [n_samples, n_features]).\n","        Y (numpy.ndarray): Training labels (shape: [n_samples]).\n","    '''\n","    self.num_samples, self.num_features = X.shape\n","    self.weights = np.zeros(self.num_features)\n","    self.bias = 0\n","\n","    for _ in range(self.n_iters):\n","      y_num_prediction = np.dot(X, self.weights) + self.bias\n","      y_predicted = self.sigmoid(y_num_prediction)\n","\n","      # Derivative of loss function\n","      dw = np.dot(X.T,(y_predicted - Y))/self.num_samples\n","      db = np.mean((y_predicted - Y))\n","\n","      # Adjustment weights and bias after each iteration\n","      self.weights = self.weights - self.learning_rate * dw\n","      self.bias = self.bias - self.learning_rate * db\n","\n","      # Stopping condition with eculidean normalisation\n","      if np.linalg.norm(db) < 0.001 and np.linalg.norm(dw) < 0.001:\n","        break # Minimum has been derived\n","\n","  def score(self, x_test,y_test):\n","    '''\n","    Scoring function which tells us the confusion metrics (Accuracy) of our model\n","    '''\n","\n","    # Deducing model prediction\n","    y_num_prediction = np.dot(x_test, self.weights) + self.bias\n","    self.y_predicted = self.sigmoid(y_num_prediction)\n","\n","    # Addition of decision thresold to get standard decsion (1 or 0)\n","    self.y_predicted = np.where(self.y_predicted > 0.5, 1, 0)\n","    accuracy =  np.mean(self.y_predicted == y_test)\n","    return accuracy\n","\n","# Importing algorithm\n","from imblearn.over_sampling import ADASYN\n","adasyn = ADASYN(random_state=42)\n","\n","# Resampling of Futures and Lables\n","x_train_bal, y_train_bal = adasyn.fit_resample(x_train,y_train)\n","\n","'''TESTING OUT DATA SET TROUGHT ALGORITHMS '''\n","#note: Recall will be much important than precision for this model\n","\n","#import models\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBRFClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.model_selection import cross_val_score\n","#importing scoring matrics\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import recall_score, precision_score, f1_score\n","#importing grid_test\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","\n","# train models and store them in a dictionary\n","possible_algorithms = {\n","    # \"Logistic Regression\": LogisticRegression(),\n","    # \"XGBoost RF\": XGBRFClassifier(n_estimators=100, random_state=42)\n","    # \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42)\n","}\n","\n","# loop through the dictonary\n","# for alg_name,model in possible_algorithms.items():\n","#   print(f\"{alg_name} \\n\")\n","#   f1 = cross_val_score(model, x_train_bal, y_train_bal, cv=5, scoring= 'f1').mean()\n","#   recall = cross_val_score(model, x_train_bal, y_train_bal, cv=5, scoring='recall').mean()\n","#   precision = cross_val_score(model, x_train_bal, y_train_bal, cv=5, scoring='precision').mean()\n","\n","#   print(f\"The f1 score for {alg_name} = {f1:.4f}\")\n","#   print(f\"The recall score for {alg_name} = {recall:.4f}\")\n","#   print(f\"The precision score for {alg_name} = {precision:.4f}\\n\")\n","\n","\n","\"\"\"STAND ALONE TEST ON RANDOMFORESTCLASSIFIER\"\"\"\n","#Hyperparameter tunning\n","from sklearn.model_selection import RandomizedSearchCV\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'class_weight': [{0:1, 1:1.5}]  # Keep current class weight\n","}\n","grid_result =RandomizedSearchCV(RandomForestClassifier(random_state=42),param_grid,scoring=\"f1\",cv=5,n_jobs=-1,random_state=42,)\n","grid_result.fit(x_train_bal,y_train_bal)\n","ideal_model = grid_result.best_estimator_\n","\n","print(f\"Best parameters: {grid_result.best_params_}\")\n","print(f\"Best Cross-Validation Recall: {grid_result.best_score_:.4f}\")\n","\n","y_prob = ideal_model.predict_proba(x_test)[:, 1]\n","#adjusting threshold\n","threshold = 0.4\n","y_pred = (y_prob >= threshold).astype(int)\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n","print(f\"Confusion Matrix: [TN={confusion_matrix(y_test, y_pred).ravel()[0]}, FP={confusion_matrix(y_test, y_pred).ravel()[1]}, FN={confusion_matrix(y_test, y_pred).ravel()[2]}, TP={confusion_matrix(y_test, y_pred).ravel()[3]}\")\n","print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n","print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n","print(f\"F1_score: {f1_score(y_test, y_pred):.4f}\")\n","\n","\n","# bins = [0,15,48,73]\n","# labels = [\"New_customers\", \"Established_customers\", \"Loyal_customers\"]\n","# df_tele['Tenure_Group'] = pd.cut(df_tele['tenure'], bins=bins, labels=labels, right=False)\n","# df_tele['HighRisk_Interaction'] = ((df_tele['Contract'] == 'Month-to-month') & (df_tele['InternetService'] == 'Fiber optic')).astype(int)\n","\n","# threshold = 0.4\n","# Best parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20, 'class_weight': {0: 1, 1: 1.5}}\n","# Best Cross-Validation Recall: 0.8335\n","# Accuracy: 0.7257\n","# Confusion Matrix: [TN=736, FP=297, FN=89, TP=285\n","# Recall: 0.7620\n","# Precision: 0.4897\n","# F1_score: 0.5962\n","\n","#threshold = 0.35\n","# Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","# Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20, 'class_weight': {0: 1, 1: 1.5}}\n","# Best Cross-Validation Recall: 0.8317\n","# Accuracy: 0.7129\n","# Confusion Matrix: [TN=700, FP=333, FN=71, TP=303\n","# Recall: 0.8102\n","# Precision: 0.4764\n","# F1_score: 0.6000\n","\n","#threshold = 0.4 with engineered feature tenure_monthly_charges\n","# Best parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'class_weight': {0: 1, 1: 1.5}}\n","# Best Cross-Validation Recall: 0.8325\n","# Accuracy: 0.7306\n","# Confusion Matrix: [TN=748, FP=285, FN=94, TP=280\n","# Recall: 0.7487\n","# Precision: 0.4956\n","# F1_score: 0.5964"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"PydQFsekTQ53","executionInfo":{"status":"ok","timestamp":1752843737676,"user_tz":-60,"elapsed":9,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}}},"outputs":[],"source":["\n"]},{"cell_type":"code","source":[],"metadata":{"id":"JY9z-3OSMeYi"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTVM1z8YH8hCQ7zcddvhPJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}