{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSWG7S+cbNLAtLnE6qePgt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !ssh-keygen -t rsa -b 4096 -C \"fabianbernard49@gmail.com\" -f ~/.ssh/id_rsa -N \"\" # create ssh pair key\n","# !cat ~/.ssh/id_rsa.pub # print it out\n","!ssh-keyscan -H github.com >> ~/.ssh/known_hosts # make github a knownhost\n","!ssh -T git@github.com #aunthenticate github\n","!git config --global user.name \"coded-by-49\" # make yourself a known host\n","!git config --global user.email \"fabianbernard49@gmail.com\"\n","%cd /content/drive/MyDrive/Git_repos\n","!git clone git@github.com:coded-by-49/Telecom-churn-model.git"],"metadata":{"id":"cTN7maFWg2rM","executionInfo":{"status":"ok","timestamp":1752581488070,"user_tz":-60,"elapsed":2436,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"572cda7e-7076-4dc5-d62d-4c4144ca4830"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["# github.com:22 SSH-2.0-da7dc22f\n","# github.com:22 SSH-2.0-da7dc22f\n","# github.com:22 SSH-2.0-da7dc22f\n","# github.com:22 SSH-2.0-da7dc22f\n","# github.com:22 SSH-2.0-da7dc22f\n","Hi coded-by-49! You've successfully authenticated, but GitHub does not provide shell access.\n","/content/drive/MyDrive/Git_repos\n","Cloning into 'Telecom-churn-model'...\n","remote: Enumerating objects: 19, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 19 (delta 4), reused 8 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (19/19), 10.74 KiB | 1.34 MiB/s, done.\n","Resolving deltas: 100% (4/4), done.\n"]}]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfQaQpg8efAJ","executionInfo":{"status":"ok","timestamp":1752581708123,"user_tz":-60,"elapsed":4979,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"31cc31ec-921f-45cf-82d6-f4f1dbd51986"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Accuracy on test models: 0.7903340440653873\n","Confusion matrix = {'TP': 171, 'TN': 941, 'FP': 92, 'FN': 203}\n"]}],"source":["from itertools import groupby\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","from IPython.display import clear_output\n","import tensorflow as tf\n","fc = tf.compat.v2.feature_column\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# GET OUR THE FILE READY\n","from google.colab import drive\n","import urllib\n","drive.mount('/content/drive')\n","tele_file = \"/content/drive/MyDrive/GOOGLE COLLAB PROJECTS/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n","df_tele = pd.read_csv(tele_file)\n","\n","# LEARNIN ALGORITHM\n","from sklearn.linear_model import LogisticRegression\n","df_tele.drop(\"customerID\", axis = 1, inplace = True) # removed this unimportant feature\n","\n","# CLEANING OF DATA\n","df_tele[\"TotalCharges\"] = df_tele[\"TotalCharges\"].replace(\" \", np.nan) # replacing empty strings np.nan, to that i can convert it to float\n","df_tele.dropna(subset = [\"TotalCharges\"], inplace=True) # cleaded out the array by dropping does empty values within the Totalcharges feature\n","df_tele[\"TotalCharges\"] = pd.to_numeric(df_tele[\"TotalCharges\"]) # coverted to float because of the kind of content within totalcharges\n","\n","# ENCODING OF ALL CATEGORICAL FEATURES\n","encoded = pd.get_dummies(df_tele, drop_first= True ) # this is one-hot key encoding (we want to transform all our categorical columns into )\n","encoded.head()\n","\n","# CHANGING THE DATATYPE OF BINARY CATEGORICAL FEATURES\n","bool_cols = encoded.select_dtypes(include = \"bool\").columns #select all columns with bool datatype\n","encoded[bool_cols] = encoded[bool_cols].astype(int) #change all of them to int (0 and 1)\n","\n","encoded[\"tenure\"] = encoded[\"tenure\"].astype(float)\n","all_numerical_features = encoded.select_dtypes(include = np.number).columns.tolist()\n","\n","needed_numerical_feature = [feature for feature in all_numerical_features if encoded[feature].nunique()>2] # getting the numerical feature titles ready\n","\n","Labels = encoded[\"Churn_Yes\"]\n","Features = encoded.drop(\"Churn_Yes\", axis = 1)\n","\n","# OBTANING OUR TRANING AND TEST DATA\n","X_train, X_test, Y_train, Y_test = train_test_split(Features,Labels, test_size = 0.2, random_state = 42 )\n","# SCALLING AND PREPARING OUR TRAINING AND TESTING DATA\n","Scaler = StandardScaler()\n","\n","# let us fit and tranform  our training numerical-features\n","X_train[needed_numerical_feature] = Scaler.fit_transform(X_train[needed_numerical_feature])\n","\n","# let us apply the scaling parameters gotten from above and fit it to our testing numerical-features\n","X_test[needed_numerical_feature] = Scaler.transform(X_test[needed_numerical_feature])\n","\n","log_regression = LogisticRegression(max_iter=1000) # is max_iter really needed?\n","log_regression.fit(X_train, Y_train) # FIT THIS WHERE OUR WEIGHT AND BIAS ARE DERVIED FROM\n","\n","# print(f\"Testing accuracy: {log_regression.score(X_test, Y_test)}\") # SCORE THE TEST DATA\n","\n","# LOGISTC REGRESSION FROM SCRATCH\n","\n","class Logistic_regression:\n","  def __init__(self, learning_rate = 0.01, n_iters = 1000):\n","    self.learning_rate = learning_rate\n","    self.n_iters = n_iters\n","\n","  def sigmoid(self,z):\n","    return 1/(1+np.exp(-z))\n","\n","  '''\n","  CORE\n","  This is responsible deriving weight and bias of a several feature(s).\n","  This is important, because when we want to derive predictions on any future dataset this are the exact values we will use\n","  '''\n","\n","  def fit(self,X,Y):\n","    self.num_samples, self.num_features = X.shape #lets count the number of features and dataitems(rows)\n","    self.weights = np.zeros(self.num_features)\n","    self.bias = 0\n","\n","    for _ in range(self.n_iters):\n","      Y_num_prediction = np.dot(X, self.weights) + self.bias\n","      Y_predicted = self.sigmoid(Y_num_prediction)\n","\n","      # implementing gradient descent\n","\n","      # we are implementing the average our two derivatives of the loss function\n","      dw = np.dot(X.T,(Y_predicted - Y))/self.num_samples\n","      db = np.mean((Y_predicted - Y))\n","\n","      # adjust weights after each iteration with learning rate\n","      self.weights = self.weights - self.learning_rate * dw\n","      self.bias = self.bias - self.learning_rate * db\n","\n","      # stoping condition with eculidean normalisation\n","      if np.linalg.norm(db) < 0.001 and np.linalg.norm(dw) < 0.001:\n","        break\n","\n","# This function is used for determining the accuracy score\n","  def score(self, X_test,Y_test):\n","    Y_num_prediction = np.dot(X_test, self.weights) + self.bias\n","    self.Y_predicted = self.sigmoid(Y_num_prediction)\n","    self.Y_predicted = np.where(self.Y_predicted > 0.5, 1, 0)\n","    accuracy =  np.mean(self.Y_predicted == Y_test)\n","    return accuracy\n","\n","  def Confusion_matrix(self,predicted_class,actual_class):\n","    confusion_matrix = {\n","    'TP': 0,\n","    'TN': 0,\n","    'FP': 0,\n","    'FN': 0\n","    }\n","    for i in range(len(actual_class)):\n","      if predicted_class[i] == actual_class.iloc[i]:\n","        if predicted_class[i] == 1:\n","            confusion_matrix[\"TP\"] += 1\n","        else:\n","            confusion_matrix[\"TN\"] += 1\n","      else:\n","        if actual_class.iloc[i] == 0:\n","            confusion_matrix[\"FP\"] += 1\n","        else:\n","            confusion_matrix[\"FN\"] += 1\n","    return confusion_matrix\n","\n","test_model = Logistic_regression()\n","test_model.fit(X_train, Y_train)\n","print(f\"Accuracy on test models: {test_model.score(X_test,Y_test)}\")\n","\"TESTING MY CONFUSION MATRIX\"\n","predicted_class = test_model.Y_predicted\n","actual_class = Y_test\n","print(f\"Confusion matrix = {test_model.Confusion_matrix(predicted_class,actual_class)}\")"]},{"cell_type":"code","source":["# %cd /content/drive/MyDrive/Git_repos/Telecom-churn-model/\n","\n","!cp \"/content/drive/MyDrive/Colab Notebooks/Tele_churn.ipynb\" /content/drive/MyDrive/Git_repos/Telecom-churn-model/\n","!git status\n","!git add Tele_churn.ipynb\n","!git commit -m \"Proper update to git hu\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iiem80w5AoSx","executionInfo":{"status":"ok","timestamp":1752582452459,"user_tz":-60,"elapsed":657,"user":{"displayName":"Henry Aloh Fabian","userId":"00863304101285682802"}},"outputId":"7bcc4039-c895-4a79-815b-2f2f2d92bb7b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mTele_churn.ipynb\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MeuPuk2ODDbA"},"execution_count":null,"outputs":[]}]}